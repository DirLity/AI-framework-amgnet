{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac18f227-bc4d-406c-881e-32950f60f691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Processing ./torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl\n",
      "Installing collected packages: torch-cluster\n",
      "Successfully installed torch-cluster-1.5.9\n",
      "\u001B[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/PyTorch-1.10.2/bin/python3.7 -m pip install --upgrade pip' command.\u001B[0m\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Processing ./torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl\n",
      "Installing collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.0.9\n",
      "\u001B[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/PyTorch-1.10.2/bin/python3.7 -m pip install --upgrade pip' command.\u001B[0m\n",
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Processing ./torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: scipy in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from torch-sparse==0.6.12) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from scipy->torch-sparse==0.6.12) (1.19.5)\n",
      "Installing collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.12\n",
      "\u001B[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/PyTorch-1.10.2/bin/python3.7 -m pip install --upgrade pip' command.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl\n",
    "!pip install torch_sparse-0.6.12-cp37-cp37m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0891cda5-381e-403f-a3b0-560ce5599428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: torch-cluster===1.5.9 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (1.5.9)\n",
      "Collecting torch-geometric===2.0.2\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/05/52/b0bf572b72fb3fd0b57eabd3c46f25d128579c586dfbe25cc4f9d4163306/torch_geometric-2.0.2.tar.gz (325 kB)\n",
      "\u001B[K     |████████████████████████████████| 325 kB 34.6 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied: torch-scatter===2.0.9 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (2.0.9)\n",
      "Requirement already satisfied: torch-sparse===0.6.12 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (0.6.12)\n",
      "Collecting pyamg\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/f9/51/ec211972039f1765e9e643af69db1ab90598d84ec7749164e09f79893af7/pyamg-5.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
      "\u001B[K     |████████████████████████████████| 1.9 MB 15.3 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied: numpy in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from torch-geometric===2.0.2) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from torch-geometric===2.0.2) (4.64.1)\n",
      "Requirement already satisfied: scipy in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from torch-geometric===2.0.2) (1.5.2)\n",
      "Requirement already satisfied: networkx in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from torch-geometric===2.0.2) (2.6.3)\n",
      "Requirement already satisfied: scikit-learn in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from torch-geometric===2.0.2) (0.22.1)\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from torch-geometric===2.0.2) (2.27.1)\n",
      "Requirement already satisfied: pandas in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from torch-geometric===2.0.2) (1.1.5)\n",
      "Collecting rdflib\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/af/92/d7fb1d7fb70c9f7003fa50b7a3880ebcb311cc3f8552b3595e7c8f75aeeb/rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
      "\u001B[K     |████████████████████████████████| 528 kB 30.4 MB/s eta 0:00:01\n",
      "\u001B[?25hCollecting googledrivedownloader\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/3a/5c/485e8724383b482cc6c739f3359991b8a93fb9316637af0ac954729545c9/googledrivedownloader-0.4-py2.py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: jinja2 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from torch-geometric===2.0.2) (3.0.1)\n",
      "Requirement already satisfied: pyparsing in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from torch-geometric===2.0.2) (3.0.9)\n",
      "Collecting yacs\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: PyYAML in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from torch-geometric===2.0.2) (5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from jinja2->torch-geometric===2.0.2) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from pandas->torch-geometric===2.0.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from pandas->torch-geometric===2.0.2) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->torch-geometric===2.0.2) (1.16.0)\n",
      "Collecting importlib-metadata<5.0.0,>=4.0.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/d0/98/c277899f5aa21f6e6946e1c83f2af650cbfee982763ffb91db07ff7d3a13/importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "Collecting isodate<0.7.0,>=0.6.0\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/b6/85/7882d311924cbcfc70b1890780763e36ff0b140c7e51c110fc59a532f087/isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "\u001B[K     |████████████████████████████████| 41 kB 16.2 MB/s eta 0:00:01\n",
      "\u001B[?25hRequirement already satisfied: zipp>=0.5 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from importlib-metadata<5.0.0,>=4.0.0->rdflib->torch-geometric===2.0.2) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from importlib-metadata<5.0.0,>=4.0.0->rdflib->torch-geometric===2.0.2) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from requests->torch-geometric===2.0.2) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from requests->torch-geometric===2.0.2) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from requests->torch-geometric===2.0.2) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from requests->torch-geometric===2.0.2) (3.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages (from scikit-learn->torch-geometric===2.0.2) (1.2.0)\n",
      "Building wheels for collected packages: torch-geometric\n",
      "  Building wheel for torch-geometric (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.0.2-py3-none-any.whl size=535547 sha256=9b9c9da8838634468df77ae90216bc44142f322a71e38c732d47efec18a7e02a\n",
      "  Stored in directory: /home/ma-user/.cache/pip/wheels/6d/f6/f7/176a3c99c3b84c4d5890bf983263779376c8cad1028d8f4d04\n",
      "Successfully built torch-geometric\n",
      "Installing collected packages: isodate, importlib-metadata, yacs, rdflib, googledrivedownloader, torch-geometric, pyamg\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 5.0.0\n",
      "    Uninstalling importlib-metadata-5.0.0:\n",
      "      Successfully uninstalled importlib-metadata-5.0.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "modelarts 1.4.31 requires lxml==5.1.0, but you have lxml 4.9.1 which is incompatible.\n",
      "modelarts 1.4.31 requires matplotlib==3.5.2, but you have matplotlib 3.5.1 which is incompatible.\n",
      "modelarts 1.4.31 requires psutil==5.9.5, but you have psutil 5.8.0 which is incompatible.\n",
      "modelarts 1.4.31 requires typing-extensions==4.7.1, but you have typing-extensions 4.4.0 which is incompatible.\n",
      "cookiecutter 2.6.0 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\n",
      "sqlalchemy 2.0.41 requires typing-extensions>=4.6.0, but you have typing-extensions 4.4.0 which is incompatible.\u001B[0m\n",
      "Successfully installed googledrivedownloader-0.4 importlib-metadata-4.13.0 isodate-0.6.1 pyamg-5.0.1 rdflib-6.3.2 torch-geometric-2.0.2 yacs-0.1.8\n",
      "\u001B[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/PyTorch-1.10.2/bin/python3.7 -m pip install --upgrade pip' command.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-cluster===1.5.9 torch-geometric===2.0.2 torch-scatter===2.0.9 torch-sparse===0.6.12 pyamg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b05b713-681b-4ffc-9fb2-92a1b171fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import functools\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.spatial.qhull\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch_geometric\n",
    "import torch_scatter\n",
    "import torch_sparse\n",
    "import pyamg\n",
    "   \n",
    "from torch_geometric.utils import (\n",
    "   to_scipy_sparse_matrix,\n",
    "   add_remaining_self_loops,\n",
    "   remove_self_loops,\n",
    "   to_dense_adj,\n",
    "   subgraph,\n",
    "   from_scipy_sparse_matrix\n",
    ")\n",
    "from torch_geometric.nn import knn_interpolate\n",
    "from torch_geometric.data import Data, Batch, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "   \n",
    "from pyamg.classical.split import RS, CLJP\n",
    "\n",
    "from torch_scatter.composite import scatter_softmax\n",
    "\n",
    "from torch_sparse import SparseTensor, coalesce, transpose, spspmm\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import math,copy\n",
    "from os import PathLike\n",
    "from typing import Sequence, Dict, Union, Tuple, List\n",
    "from torch._six import string_classes\n",
    "import collections.abc as container_abcs\n",
    "from scipy.spatial.qhull import Delaunay\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import utils\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "device=torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ab983f-77d7-47e8-a562-c483a8e91cdd",
   "metadata": {},
   "source": [
    "# AMGNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5507a6e3-e023-4be0-86eb-bd33457cbc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcorsenode(latent_graph):\n",
    "    A=to_scipy_sparse_matrix(latent_graph.edge_index).tocsr()\n",
    "    splitting=RS(A)\n",
    "    index=np.array(np.nonzero(splitting))\n",
    "    b = torch.from_numpy(index)\n",
    "    b=torch.squeeze(b)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997bd083-2076-483a-bf7a-8c3d10125837",
   "metadata": {},
   "source": [
    "getcorsenode函数将输入图转换为稀疏矩阵，然后应用 Ruge-Stubbe 分裂算法来识别图中的“粗”节点，最后将这些节点的索引以 PyTorch 张量的形式返回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95007d74-b2c2-4681-b0fb-035916200b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StAS(index_A, value_A, index_S, value_S,N, kN,nor):\n",
    "\n",
    "    index_A, value_A = coalesce(index_A, value_A, m=N, n=N)\n",
    "    index_S, value_S = coalesce(index_S, value_S, m=N, n=kN)\n",
    "    index_B, value_B = spspmm(index_A, value_A, index_S, value_S, N, N, kN)\n",
    "    index_St, value_St = transpose(index_S, value_S, N, kN)\n",
    "    index_B, value_B = coalesce(index_B, value_B, m=N, n=kN)                             \n",
    "    index_E, value_E = spspmm(index_St, value_St, index_B, value_B, kN, N, kN)\n",
    "\n",
    "    return index_E, value_E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4df60f-b7a4-4358-90ec-8c035624f57f",
   "metadata": {},
   "source": [
    "StAS函数计算了稀疏矩阵 $S^T * A * S$。它首先规范化输入矩阵，然后分两步进行稀疏矩阵乘法：先计算 $A * S$，再计算 $S^T * (A * S)$。中间结果和最终结果都保持了稀疏格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cda8464-a40b-4723-8877-cb5664e9791c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_connectivity(perm, edge_index, edge_weight, score, pos, N, nor):\n",
    "    \n",
    "    # 获取被选中的节点数量\n",
    "    kN = perm.size(0)\n",
    "    perm2 = perm.view(-1, 1)\n",
    "    \n",
    "    # 创建一个布尔掩码，标识哪些边起源于 perm (选中的) 节点\n",
    "    mask = (edge_index[0] == perm2).sum(0, dtype=torch.bool)\n",
    "    \n",
    "    # 创建 S 矩阵\n",
    "    # S0: 选中的节点连接的邻居节点索引\n",
    "    S0 = edge_index[1][mask].view(1, -1)\n",
    "    # S1: 选中的节点索引\n",
    "    S1 = edge_index[0][mask].view(1, -1)\n",
    "    index_S = torch.cat([S0, S1], dim=0)\n",
    "    value_S = score[mask].detach().squeeze()\n",
    "    \n",
    "    # 重新标记用于池化的索引，使 S 的形状为 [N x kN]\n",
    "    n_idx = torch.zeros(N, dtype=torch.long)\n",
    "    # 将 perm 索引映射到新的索引范围\n",
    "    n_idx[perm] = torch.arange(perm.size(0))\n",
    "    index_S[1] = n_idx[index_S[1]]\n",
    "\n",
    "    # 获取子图节点的位置信息\n",
    "    subgraphnode_pos = pos[perm].cpu()\n",
    "    subgraphnode_pos = subgraphnode_pos.to(device)\n",
    "    \n",
    "    # 创建 A 矩阵\n",
    "    # 复制原始的边索引\n",
    "    index_A = edge_index.clone()\n",
    "    # 生成边权重 value_A\n",
    "    if edge_weight is None:\n",
    "        value_A = value_S.new_ones(edge_index[0].size(0))\n",
    "    else:\n",
    "        value_A = edge_weight.clone()\n",
    "    value_A = torch.squeeze(value_A)\n",
    "\n",
    "    # 初始化属性列表\n",
    "    attrlist = []\n",
    "\n",
    "    for i in range(128):\n",
    "        # 调用 StAS 函数，计算新的边索引和属性\n",
    "        index_E, value_E = StAS(index_A, value_A[:, i], index_S, value_S, N, kN, nor)\n",
    "        index_E, value_E = remove_self_loops(edge_index=index_E, edge_attr=value_E)\n",
    "        attrlist.append(value_E)\n",
    "    # 将属性列表堆叠成一个张量\n",
    "    edge_weight = torch.stack(attrlist, dim=1)\n",
    "    \n",
    "    return index_E, edge_weight, subgraphnode_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a6db0-8855-4bef-94c0-c4ecb4753190",
   "metadata": {},
   "source": [
    "graph_connectivity 函数通过利用原始图的连接结构、边权重和边的贡献分数，使用稀疏矩阵乘法 (StAS) 将原始图的连接性信息投影到池化后的子图上，从而为子图生成新的、信息丰富的边权重。这个过程是自适应结构感知池化 (ASAP) 方法的一部分，旨在学习层次化的图表示。\n",
    "1. **识别相关边:** 首先，函数识别出所有起点（或终点，取决于 `mask` 的具体含义）位于被选中节点（`perm`）的边。\n",
    "2. **构建投影矩阵 S:** 使用这些相关边的终点（或起点）作为索引，并使用这些边对应的 `score` 作为权重，构建一个稀疏矩阵 S。这个矩阵 S 代表了从原始图到子图的投影关系。为了适应池化操作，对 S 的索引进行了重新标记。\n",
    "3. **准备原始图的邻接矩阵 A:** 使用原始图的边索引，并根据是否提供了 `edge_weight` 来决定邻接矩阵 A 的权重（如果未提供，则使用全1权重）。\n",
    "4. **计算子图连接性:** 这是核心步骤。函数通过多次调用 `StAS` 函数来计算子图的连接性权重。`StAS` 计算的是 `S^T A S`（S的转置乘以A再乘以S）。这个操作将原始图的连接性信息（通过 A 表示）通过投影矩阵 S 映射到子图空间。`StAS` 被调用多次（示例中是128次），可能是为了处理不同类型的特征或属性。\n",
    "5. **后处理:** 对 `StAS` 的结果进行后处理，例如移除自环（self-loops）。\n",
    "6. **输出:** 最终，函数返回子图的边索引 (`index_E`)、计算得到的新边权重 (`edge_weight`) 以及子图中节点的位置信息 (`subgraphnode_pos`)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c2783a-81a2-4987-828c-25c1db076db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNetBlock(nn.Module):\n",
    "    \"\"\"具有残差连接的多边缘交互网络\"\"\"\n",
    "\n",
    "    def __init__(self, model_fn, output_size, message_passing_aggregator, attention=False):\n",
    "        super().__init__()\n",
    "        self.edge_model = model_fn(output_size)\n",
    "        self.node_model = model_fn(output_size)\n",
    "        self.message_passing_aggregator = message_passing_aggregator\n",
    "\n",
    "    def _update_edge_features(self, graph):\n",
    "        \"\"\"聚合节点特征，并应用边缘功能\"\"\"\n",
    "        senders = graph.edge_index[0].to(device)\n",
    "        receivers = graph.edge_index[1].to(device)\n",
    "        sender_features = torch.index_select(input=graph.x, dim=0, index=senders)\n",
    "        receiver_features = torch.index_select(input=graph.x, dim=0, index=receivers)\n",
    "        features = [sender_features, receiver_features, graph.edge_attr]\n",
    "        features = torch.cat(features, dim=-1)\n",
    "        return self.edge_model(features)\n",
    "\n",
    "    def unsorted_segment_operation(self, data, segment_ids, num_segments, operation):\n",
    "        \"\"\"\n",
    "        计算张量线段的和。类似于 tf.unsorted_segment_sum。\n",
    "\n",
    "        :param data： 张量，需要对其进行分段求和。\n",
    "        :param segment_ids： 分段索引张量。\n",
    "        :param num_segments： 线段的数量。\n",
    "        :return： 与数据参数类型相同的张量。\n",
    "        \"\"\"\n",
    "        assert all([i in data.shape for i in segment_ids.shape]), \"segment_ids.shape should be a prefix of data.shape\"\n",
    "\n",
    "        # segment_ids is a 1-D tensor repeat it to have the same shape as data\n",
    "        if len(segment_ids.shape) == 1:\n",
    "            s = torch.prod(torch.tensor(data.shape[1:])).long().to(device)\n",
    "            segment_ids = segment_ids.repeat_interleave(s).view(segment_ids.shape[0], *data.shape[1:]).to(device)\n",
    "\n",
    "        assert data.shape == segment_ids.shape, \"data.shape and segment_ids.shape should be equal\"\n",
    "\n",
    "        shape = [num_segments] + list(data.shape[1:])\n",
    "        result = torch.zeros(*shape)\n",
    "        if operation == 'sum':\n",
    "            result = torch_scatter.scatter_add(data.float(), segment_ids, dim=0, dim_size=num_segments)\n",
    "        elif operation == 'max':\n",
    "            result, _ = torch_scatter.scatter_max(data.float(), segment_ids, dim=0, dim_size=num_segments)\n",
    "        elif operation == 'mean':\n",
    "            result = torch_scatter.scatter_mean(data.float(), segment_ids, dim=0, dim_size=num_segments)\n",
    "        elif operation == 'min':\n",
    "            result, _ = torch_scatter.scatter_min(data.float(), segment_ids, dim=0, dim_size=num_segments)\n",
    "        result = result.type(data.dtype)\n",
    "        return result\n",
    "\n",
    "    def _update_node_features(self, node_features, edge_attr, edge_index):\n",
    "        \"\"\"聚合边缘特征，并应用节点功能\"\"\"\n",
    "        num_nodes = node_features.shape[0]\n",
    "        features = [node_features]\n",
    "        features.append(\n",
    "            self.unsorted_segment_operation(edge_attr, edge_index[1], num_nodes,\n",
    "                                            operation=self.message_passing_aggregator))\n",
    "        features = torch.cat(features, dim=-1)\n",
    "        return self.node_model(features)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        \"\"\"应用 GraphNetBlock 并返回更新后的 MultiGraph\"\"\"\n",
    "        new_edge_features = self._update_edge_features(graph)\n",
    "        new_node_features = self._update_node_features(graph.x, graph.edge_attr, graph.edge_index)\n",
    "\n",
    "        new_node_features += graph.x\n",
    "        new_edge_features += graph.edge_attr\n",
    "        return Data(x=new_node_features, pos=graph.pos, edge_attr=graph.edge_attr,\n",
    "                    edge_index=graph.edge_index, batch=graph.batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f275e475-5c4d-4ceb-be69-6bb7222f4aa5",
   "metadata": {},
   "source": [
    "GraphNetBlock 是一个典型的图神经网络块，它通过边更新和节点更新两个步骤来传递和聚合信息，并使用残差连接来增强学习能力和稳定性。它允许网络在每一层都学习节点和边之间的复杂交互关系，是构建更深层次图神经网络的基础单元。\n",
    "### 模块结构\n",
    "1.  **初始化 (`__init__`)**:\n",
    "    *   接收参数：`model_fn`（一个用于创建子模型的函数，通常是 MLP）、`output_size`（输出特征维度）、`message_passing_aggregator`（消息聚合方式，如 'sum', 'mean', 'max' 等）、`attention`（是否使用注意力机制，代码中相关部分被注释掉了）。\n",
    "    *   成员变量：\n",
    "        *   `edge_model`: 通过 `model_fn` 创建，用于更新边的特征。\n",
    "        *   `node_model`: 通过 `model_fn` 创建，用于更新节点的特征。\n",
    "        *   `message_passing_aggregator`: 存储消息聚合方式。\n",
    "        *   `attention_model`: (注释掉) 如果使用注意力机制，会创建一个注意力模型。\n",
    "2.  **内部方法**:\n",
    "    *   `_update_edge_features(graph)`: 负责更新图中的边特征。\n",
    "    *   `unsorted_segment_operation(data, segment_ids, num_segments, operation)`: 一个辅助函数，实现类似 TensorFlow 中 `unsorted_segment_sum` 的功能，用于对张量进行分段求和、求最大值、求平均值等操作。它使用了 `torch_scatter` 库。\n",
    "    *   `_update_node_features(node_features, edge_attr, edge_index)`: 负责更新图中的节点特征。\n",
    "3.  **前向传播 (`forward`)**: 定义了模块接收输入（图数据）并产生输出（更新后的图数据）的计算过程。\n",
    "### 功能\n",
    "`GraphNetBlock` 的核心功能是执行图神经网络中的一个基本计算步骤，它包含两个主要的更新过程和一个残差连接：\n",
    "1.  **边特征更新 (`_update_edge_features`)**:\n",
    "    *   对于图中的每条边，它获取该边的两个端点（发送节点和接收节点）的特征，以及该边自身的特征。\n",
    "    *   将这些特征拼接在一起，形成一个组合特征向量。\n",
    "    *   将这个组合特征向量输入到 `edge_model` 中，得到更新后的边特征。\n",
    "2.  **节点特征更新 (`_update_node_features`)**:\n",
    "    *   对于图中的每个节点，它首先保留节点自身的原始特征。\n",
    "    *   然后，它收集与该节点相连的所有边的更新后特征（通过 `unsorted_segment_operation` 函数，根据边的接收节点索引进行聚合，聚合方式由 `message_passing_aggregator` 决定）。\n",
    "    *   将节点自身的特征和聚合后的边特征拼接在一起。\n",
    "    *   将这个组合特征向量输入到 `node_model` 中，得到更新后的节点特征。\n",
    "3.  **残差连接 (Residual Connection)**:\n",
    "    *   在得到新的节点特征和边特征后，将它们与输入图中的原始节点特征和原始边特征相加。这有助于稳定训练过程，并允许网络学习恒等映射。\n",
    "4.  **输出**:\n",
    "    *   模块最终返回一个新的图数据对象 `Data`，其中包含了更新后的节点特征 (`new_node_features`)、原始的位置信息 (`graph.pos`)、更新后的边特征 (`new_edge_features`)、原始的边索引 (`graph.edge_index`) 和原始的批处理信息 (`graph.batch`)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8b7677-2845-4333-83ca-5c490c91053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_nodes = 2000  # 每个网格的粗化点都少于此值\n",
    "\n",
    "class Processor(nn.Module):\n",
    "\n",
    "    def __init__(self, make_mlp, output_size, message_passing_steps, message_passing_aggregator, attention=False,\n",
    "                 stochastic_message_passing_used=False):\n",
    "        super().__init__()\n",
    "        self.stochastic_message_passing_used = stochastic_message_passing_used\n",
    "        self.graphnet_blocks = nn.ModuleList()\n",
    "        self.cofe_edge_blocks = nn.ModuleList()\n",
    "        self.pool_blocks = nn.ModuleList()\n",
    "        self.latent_size = output_size\n",
    "        self.normalization = nn.LayerNorm(128)\n",
    "        for index in range(message_passing_steps):\n",
    "            self.graphnet_blocks.append(GraphNetBlock(model_fn=make_mlp, output_size=output_size,\n",
    "                                                      message_passing_aggregator=message_passing_aggregator,\n",
    "                                                      attention=attention))\n",
    "\n",
    "            self.pool_blocks.append(GraphNetBlock(model_fn=make_mlp, output_size=output_size,\n",
    "                                                  message_passing_aggregator=message_passing_aggregator,\n",
    "                                                  attention=attention))\n",
    "    def forward(self, latent_graph, normalized_adj_mat=None):\n",
    "        x = []\n",
    "        pos = []\n",
    "        new = []\n",
    "        for (graphnet_block, pool) in zip(self.graphnet_blocks, self.pool_blocks):\n",
    "            if latent_graph.x.shape[0] > min_nodes:\n",
    "                pre_matrix = graphnet_block(latent_graph)\n",
    "                x.append(pre_matrix)\n",
    "                cofe_graph = pool(pre_matrix)  # updata edge features\n",
    "                coarsenodes = getcorsenode(pre_matrix).to(device)\n",
    "                nodesfeatures = cofe_graph.x[coarsenodes]\n",
    "                subedge_index, edge_weight, subpos = graph_connectivity(perm=coarsenodes,\n",
    "                                                                        edge_index=cofe_graph.edge_index,\n",
    "                                                                        edge_weight=cofe_graph.edge_attr,\n",
    "                                                                        score=cofe_graph.edge_attr[:, 0],\n",
    "                                                                        pos=cofe_graph.pos,\n",
    "                                                                        N=cofe_graph.x.size(0),\n",
    "                                                                        nor=self.normalization)\n",
    "                edge_weight = self.normalization(edge_weight)\n",
    "                pos.append(subpos)\n",
    "                latent_graph = Data(x=nodesfeatures, pos=subpos,\n",
    "                                    edge_attr=edge_weight, edge_index=subedge_index)\n",
    "            else:\n",
    "                latent_graph = graphnet_block(latent_graph)\n",
    "                new.append(latent_graph)\n",
    "        if len(new):\n",
    "            x.append(new[-1])\n",
    "        return x, pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586dcac-7161-4364-9d78-513750f373e9",
   "metadata": {},
   "source": [
    "###  `Processor` 层\n",
    "`Processor` 是一个继承自 `nn.Module` 的 PyTorch 模块，用于处理图数据。它的核心思想是：\n",
    "1.  **选择关键节点:** 根据节点的特征重要性（这里使用特征平方和）选择一部分节点作为“高影响力节点”。\n",
    "2.  **建立连接:** 在每个“涟漪”（ripple）层中，将选定的节点与这些高影响力节点建立连接。这些连接（包括特征和距离信息）是可学习的。\n",
    "3.  **特征处理:** 使用一个多层感知器（MLP）来处理这些连接信息。\n",
    "4.  **整合与输出:** 将处理后的结果添加到编码器的输出（潜在图）中，然后这个修改后的图被送回原始处理器（或下一个处理阶段）。\n",
    "这个 `Processor` 类是一个 PyTorch 模块，用于处理图数据，特别是进行图神经网络中的消息传递和池化操作。它通过一系列的图神经网络块和池化块来逐步处理图数据，并在每一步中根据图的大小决定是否进行池化操作。\n",
    "\n",
    "### 类结构和功能\n",
    "\n",
    "1. **初始化 (`__init__` 方法)**:\n",
    "   - **参数**:\n",
    "     - `make_mlp`: 一个函数，用于创建多层感知机（MLP）模型。\n",
    "     - `output_size`: 输出特征的维度。\n",
    "     - `message_passing_steps`: 消息传递的步数。\n",
    "     - `message_passing_aggregator`: 消息传递的聚合方式。\n",
    "     - `attention`: 是否使用注意力机制。\n",
    "     - `stochastic_message_passing_used`: 是否使用随机消息传递。\n",
    "   - **成员变量**:\n",
    "     - `stochastic_message_passing_used`: 是否使用随机消息传递。\n",
    "     - `graphnet_blocks`: 存储图神经网络块的列表。\n",
    "     - `cofe_edge_blocks`: 存储边缘特征块的列表（在代码中被注释掉）。\n",
    "     - `pool_blocks`: 存储池化块的列表。\n",
    "     - `latent_size`: 输出特征的维度。\n",
    "     - `normalization`: 层归一化层。\n",
    "   - **初始化过程**:\n",
    "     - 根据消息传递步数，初始化图神经网络块和池化块。\n",
    "2. **前向传播 (`forward` 方法)**:\n",
    "   - **输入**:\n",
    "     - `latent_graph`: 输入的图数据。\n",
    "     - `normalized_adj_mat`: 归一化的邻接矩阵（未在代码中使用）。\n",
    "   - **输出**:\n",
    "     - `x`: 存储每一步处理后的节点特征的列表。\n",
    "     - `pos`: 存储每一步处理后的节点位置信息的列表。\n",
    "   - **处理过程**:\n",
    "     - 初始化列表 `x`, `pos`, 和 `new`。\n",
    "     - 遍历图神经网络块和池化块：\n",
    "       - 如果当前图的节点数大于 `min_nodes`，则进行消息传递和池化操作：\n",
    "         - 使用图神经网络块处理图数据。\n",
    "         - 使用池化块更新边缘特征。\n",
    "         - 获取粗节点索引。\n",
    "         - 提取粗节点的特征和位置信息。\n",
    "         - 使用 `graph_connectivity` 函数更新边的索引和权重。\n",
    "         - 更新归一化后的边权重。\n",
    "         - 更新 `latent_graph` 为新的图数据。\n",
    "       - 否则，仅使用图神经网络块处理图数据，并将结果存储在 `new` 列表中。\n",
    "     - 如果 `new` 列表不为空，将最后一个图数据添加到 `x` 列表中。\n",
    "     - 返回 `x` 和 `pos`。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "307e52fe-9b48-4df5-97e6-68c3573475d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyMLP(nn.Module):\n",
    "    def __init__(self, output_sizes):\n",
    "        super().__init__()\n",
    "        num_layers = len(output_sizes)\n",
    "        self._layers_ordered_dict = OrderedDict()\n",
    "        for index, output_size in enumerate(output_sizes):\n",
    "            self._layers_ordered_dict[\"linear_\" + str(index)] = nn.LazyLinear(output_size)\n",
    "            if index < (num_layers - 1):\n",
    "                self._layers_ordered_dict[\"relu_\" + str(index)] = nn.ReLU()\n",
    "        self.layers = nn.Sequential(self._layers_ordered_dict)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.to(device)\n",
    "        y = self.layers(input)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473d5e91-06bd-4886-9076-e841a79796fe",
   "metadata": {},
   "source": [
    "###  `LazyMLP` 类\n",
    "\n",
    "**内容:**\n",
    "\n",
    "`LazyMLP` 是一个继承自 `nn.Module` 的 PyTorch 模块，它实现了一个“懒惰”的多层感知器（MLP）。所谓“懒惰”是指它的输入维度不需要在初始化时指定，而是在第一次前向传播时根据输入数据自动推断（通过 `nn.LazyLinear` 层实现）。\n",
    "\n",
    "**参数:**\n",
    "\n",
    "*   `widths`: 一个列表，指定MLP每一层的输出维度。列表的第一个元素是输入维度（可以是任意值，因为会忽略或推断），后续元素定义了每一层的宽度，最后一个元素是最终的输出维度。例如 `[input_dim, 128, 64, output_dim]`。\n",
    "\n",
    "**内部结构:**\n",
    "\n",
    "*   `self.layers`: 一个 `nn.Sequential` 容器，包含一系列 `nn.LazyLinear` 层和 `nn.ReLU` 激活函数层（除了最后一层）。\n",
    "\n",
    "**方法:**\n",
    "\n",
    "*   `__init__(self, widths)`: 初始化方法，根据 `widths` 列表构建MLP层。\n",
    "*   `forward(self, input)`: 前向传播方法，接收输入数据，通过MLP层进行计算，并返回输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec3978e-c607-420c-8477-dac16e6dbd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, make_mlp, latent_size):\n",
    "        super().__init__()\n",
    "        self._make_mlp = make_mlp\n",
    "        self._latent_size = latent_size\n",
    "        self.node_model = self._make_mlp(latent_size)\n",
    "        self.mesh_edge_model = self._make_mlp(latent_size)\n",
    "\n",
    "    def forward(self, graph):\n",
    "        node_latents = self.node_model(graph.x)\n",
    "        edge_latent = self.mesh_edge_model(graph.edge_attr)\n",
    "        graph.x=node_latents\n",
    "        graph.edge_attr=edge_latent\n",
    "        return graph\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, make_mlp, output_size):\n",
    "        super().__init__()\n",
    "        self.model = make_mlp(output_size)\n",
    "\n",
    "    def forward(self,node_features):\n",
    "        return self.model(node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4c37c2-5696-4100-b7ce-d758fe9f291f",
   "metadata": {},
   "source": [
    "### `Encoder` 类\n",
    "`Encoder` 类负责将图中的节点和边特征编码为潜在特征（latent features）。它的结构如下：\n",
    "- **`__init__`**: 初始化方法，创建两个 MLP 模型，分别用于处理节点特征和边特征。\n",
    "- **`forward`**: 前向传播方法，将输入图的节点和边特征分别传递给对应的 MLP 模型，并更新图的特征。\n",
    "\n",
    "### `Decoder` 类\n",
    "`Decoder` 类负责将潜在特征解码为输出特征。它的结构如下：\n",
    "- **`__init__`**: 初始化方法，创建一个 MLP 模型用于处理节点特征。\n",
    "- **`forward`**: 前向传播方法，将输入的节点特征传递给 MLP 模型，并返回输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c33c7a2f-ca00-4572-923b-7bbf4e35cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeProcessDecode(nn.Module):\n",
    "    \"\"\"Encode-Process-Decode GraphNet model.\"\"\"\n",
    "    def __init__(self,\n",
    "                 output_size,\n",
    "                 latent_size,\n",
    "                 num_layers,\n",
    "                 message_passing_aggregator, message_passing_steps,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self._latent_size = latent_size\n",
    "        self._output_size = output_size\n",
    "        self._num_layers = num_layers\n",
    "        self._message_passing_steps = message_passing_steps\n",
    "        self._message_passing_aggregator = message_passing_aggregator   \n",
    "        self.encoder = Encoder(make_mlp=self._make_mlp, latent_size=self._latent_size)\n",
    "        self.processor = Processor(make_mlp=self._make_mlp, output_size=self._latent_size,\n",
    "                                   message_passing_steps=self._message_passing_steps,\n",
    "                                   message_passing_aggregator=self._message_passing_aggregator,\n",
    "                                   stochastic_message_passing_used=False)\n",
    "        self.post_processor=self._make_mlp(self._latent_size)                           \n",
    "        self.decoder = Decoder(make_mlp=functools.partial(self._make_mlp, layer_norm=False),\n",
    "                               output_size=self._output_size)\n",
    "\n",
    "    def _make_mlp(self, output_size, layer_norm=True):\n",
    "        \"\"\"Builds an MLP.\"\"\"\n",
    "        widths = [self._latent_size] * self._num_layers + [output_size]\n",
    "        network = LazyMLP(widths)\n",
    "        if layer_norm:\n",
    "            network = nn.Sequential(network, nn.LayerNorm(normalized_shape=widths[-1]))\n",
    "        return network\n",
    "\n",
    "    def spa_compute(self,x,p):\n",
    "        j=len(x)-1\n",
    "        node_features=x[j].x\n",
    "        x_pos=x[j].pos\n",
    "        for k in range(1,j+1):\n",
    "            pos=p[-k]\n",
    "            feature=knn_interpolate(node_features,pos,x[-(k+1)].pos)  \n",
    "            node_features=x[-(k+1)].x+feature                  \n",
    "            node_features=self.post_processor(node_features)\n",
    "                    \n",
    "        return node_features     \n",
    "    def forward(self, graph):\n",
    "        latent_graph = self.encoder(graph)\n",
    "        x,p= self.processor(latent_graph)\n",
    "        node_features=self.spa_compute(x,p)\n",
    "        return self.decoder(node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc633221-6b3a-4733-96b1-97f88bb94b78",
   "metadata": {},
   "source": [
    "### 定义 `EncodeProcessDecode` 类\n",
    "`EncodeProcessDecode` 是主模型类，它结合了编码器、处理器和解码器。它的结构如下：\n",
    "- **`__init__`**: 初始化方法，创建编码器、处理器和解码器实例，并定义一些参数。\n",
    "  - `encoder`: 编码器实例，用于将节点和边特征编码为潜在特征。\n",
    "  - `processor`: 处理器实例，用于在图上进行消息传递和特征更新。\n",
    "  - `post_processor`: 后处理 MLP，用于进一步处理节点特征。\n",
    "  - `decoder`: 解码器实例，用于将潜在特征解码为输出特征。\n",
    "- **`_make_mlp`**: 辅助方法，用于构建 MLP 网络。\n",
    "- **`spa_compute`**: 特殊的前向传播方法，用于处理节点特征。它使用 `knn_interpolate` 进行插值，并逐步更新节点特征。\n",
    "- **`forward`**: 前向传播方法，将输入图传递给编码器、处理器和 `spa_compute` 方法，最后通过解码器生成输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b503bb0b-18a1-4112-80b8-0eb882f8cd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "def logger_setup(log_path):\n",
    "    # set log configuration\n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.setLevel(logging.INFO)\n",
    "    # console_output_handler = logging.StreamHandler(sys.stdout)\n",
    "    # console_output_handler.setLevel(logging.INFO)\n",
    "    file_log_handler = logging.FileHandler(filename=log_path, mode='w', encoding='utf-8')\n",
    "    file_log_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter(fmt='%(asctime)s - %(message)s')\n",
    "    # console_output_handler.setFormatter(formatter)\n",
    "    file_log_handler.setFormatter(formatter)\n",
    "    # root_logger.addHandler(console_output_handler)\n",
    "    root_logger.addHandler(file_log_handler)\n",
    "    return root_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78345851-59c4-47ab-ae37-60fc4ac10c53",
   "metadata": {},
   "source": [
    "### 日志记录器\n",
    "1. **创建日志记录器**：\n",
    "   - 使用 `logging.getLogger()` 获取根日志记录器，并将其日志级别设置为 `INFO`。\n",
    "2. **配置文件日志处理器**：\n",
    "   - 创建一个 `FileHandler`，将日志写入指定的文件路径（`log_path`），模式为写入模式（`'w'`），编码为 `utf-8`。\n",
    "   - 将日志级别设置为 `INFO`。\n",
    "3. **设置日志格式**：\n",
    "   - 使用 `logging.Formatter` 设置日志格式，格式为 `'%(asctime)s - %(message)s'`，即时间戳和日志消息。\n",
    "4. **添加日志处理器**：\n",
    "   - 将文件日志处理器添加到根日志记录器中。\n",
    "5. **返回日志记录器**：\n",
    "   - 返回配置好的根日志记录器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dabd8f8-5dea-4e46-8719-1ca91309d506",
   "metadata": {},
   "source": [
    "# Airfoil数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fdda07-7d45-4325-82d2-47bc857f453c",
   "metadata": {},
   "source": [
    "## 数据集处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b00ae52-d8ac-4b1f-964f-57681b89876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import math,copy\n",
    "from os import PathLike\n",
    "from typing import Sequence, Dict, Union, Tuple, List\n",
    "import torch\n",
    "from torch._six import string_classes\n",
    "import collections.abc as container_abcs\n",
    "from torch_geometric.data import Data, Batch, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from scipy.spatial.qhull import Delaunay\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import utils\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e5a473d-334a-433d-a3de-5189393b94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SU2_SHAPE_IDS = {\n",
    "    'line': 3,\n",
    "    'triangle': 5,\n",
    "    'quad': 9,\n",
    "}\n",
    "\n",
    "def get_mesh_graph(mesh_filename: Union[str, PathLike],\n",
    "                   dtype: np.dtype = np.float32\n",
    "                   ) -> Tuple[np.ndarray, np.ndarray, List[List[List[int]]], Dict[str, List[List[int]]]]:\n",
    "    def get_rhs(s: str) -> str:\n",
    "        return s.split('=')[-1]\n",
    "\n",
    "    marker_dict = {}\n",
    "    with open(mesh_filename) as f:\n",
    "        for line in f:\n",
    "            if line.startswith('NPOIN'):\n",
    "                num_points = int(get_rhs(line))\n",
    "                mesh_points = [[float(p) for p in f.readline().split()[:2]]\n",
    "                               for _ in range(num_points)]\n",
    "                nodes = np.array(mesh_points, dtype=dtype)\n",
    "\n",
    "            if line.startswith('NMARK'):\n",
    "                num_markers = int(get_rhs(line))\n",
    "                for _ in range(num_markers):\n",
    "                    line = f.readline()\n",
    "                    assert line.startswith('MARKER_TAG')\n",
    "                    marker_tag = get_rhs(line).strip()\n",
    "                    num_elems = int(get_rhs(f.readline()))\n",
    "                    marker_elems = [[int(e) for e in f.readline().split()[-2:]]\n",
    "                                    for _ in range(num_elems)]\n",
    "                    # marker_dict[marker_tag] = np.array(marker_elems, dtype=np.long).transpose()\n",
    "                    marker_dict[marker_tag] = marker_elems\n",
    "\n",
    "            if line.startswith('NELEM'):\n",
    "                edges = []\n",
    "                triangles = []\n",
    "                quads = []\n",
    "                num_edges = int(get_rhs(line))\n",
    "                for _ in range(num_edges):\n",
    "                    elem = [int(p) for p in f.readline().split()]\n",
    "                    if elem[0] == SU2_SHAPE_IDS['triangle']:\n",
    "                        n = 3\n",
    "                        triangles.append(elem[1:1+n])\n",
    "                    elif elem[0] == SU2_SHAPE_IDS['quad']:\n",
    "                        n = 4\n",
    "                        quads.append(elem[1:1+n])\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "                    elem = elem[1:1+n]\n",
    "                    edges += [[elem[i], elem[(i+1) % n]] for i in range(n)]\n",
    "                edges = np.array(edges, dtype=np.long).transpose()\n",
    "                # triangles = np.array(triangles, dtype=np.long)\n",
    "                # quads = np.array(quads, dtype=np.long)\n",
    "                elems = [triangles, quads]\n",
    "\n",
    "\n",
    "    return nodes, edges, elems, marker_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf987d5-a56b-4eb2-910b-7dfa55729a3a",
   "metadata": {},
   "source": [
    "### 定义常量\n",
    "定义了一个常量 `SU2_SHAPE_IDS`，用于标识不同形状的网格元素（如线、三角形、四边形）。\n",
    "### 辅助函数 `get_mesh_graph`\n",
    "这个函数用于从 `.su2` 文件中读取网格数据，并返回节点坐标、边索引、元素列表和标记字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3cd4da4-2421-4c9b-ba19-76f24d72c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeshAirfoilDataset(Dataset):\n",
    "    def __init__(self, root, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.data_dir = Path(root) / ('outputs_' + mode)\n",
    "        self.file_list = os.listdir(self.data_dir)\n",
    "        self.len = len(self.file_list)\n",
    "\n",
    "        self.mesh_graph = get_mesh_graph(Path(root) / 'mesh_fine.su2')\n",
    "\n",
    "        # either [maxes, mins] or [means, stds] from data for normalization\n",
    "        # with open(self.data_dir / 'train_mean_std.pkl', 'rb') as f:\n",
    "        with open(self.data_dir.parent / 'train_max_min.pkl', 'rb') as f:\n",
    "            self.normalization_factors = pickle.load(f)\n",
    "\n",
    "        self.nodes = torch.from_numpy(self.mesh_graph[0])\n",
    "        self.edges = torch.from_numpy(self.mesh_graph[1])\n",
    "        self.elems_list = self.mesh_graph[2]\n",
    "        self.marker_dict = self.mesh_graph[3]\n",
    "        self.node_markers = self.nodes.new_full((self.nodes.shape[0], 1), fill_value=-1)\n",
    "        for i, (marker_tag, marker_elems) in enumerate(self.marker_dict.items()):\n",
    "            for elem in marker_elems:\n",
    "                self.node_markers[elem[0]] = i\n",
    "                self.node_markers[elem[1]] = i\n",
    "\n",
    "        super().__init__(root)\n",
    "        \n",
    "    def len(self):\n",
    "        return self.len\n",
    "\n",
    "    def get(self, idx):\n",
    "        with open(self.data_dir / self.file_list[idx], 'rb') as f:\n",
    "            fields = pickle.load(f)\n",
    "        fields = self.preprocess(fields)\n",
    "\n",
    "        aoa, reynolds, mach = self.get_params_from_name(self.file_list[idx])\n",
    "        aoa = aoa\n",
    "        aoa = torch.from_numpy(aoa)\n",
    "        mach_or_reynolds = mach if reynolds is None else reynolds\n",
    "        mach_or_reynolds = torch.from_numpy(mach_or_reynolds)\n",
    "\n",
    "        norm_aoa = aoa / 10\n",
    "        norm_mach_or_reynolds = mach_or_reynolds if reynolds is None else (mach_or_reynolds - 1.5e6) / 1.5e6\n",
    "\n",
    "        nodes = torch.cat([\n",
    "            self.nodes,\n",
    "            norm_aoa.unsqueeze(0).repeat(self.nodes.shape[0], 1),\n",
    "            norm_mach_or_reynolds.unsqueeze(0).repeat(self.nodes.shape[0], 1),\n",
    "            self.node_markers\n",
    "        ], dim=-1)\n",
    "\n",
    "        data = Data(x=nodes, y=fields, edge_index=self.edges,pos=self.nodes)\n",
    "\n",
    "        sender=data.x[data.edge_index[0]]\n",
    "        receiver=data.x[data.edge_index[1]]\n",
    "        relation_pos=sender[:,0:2]-receiver[:,0:2]\n",
    "        post=torch.norm(relation_pos,p=2,dim=1,keepdim=True)\n",
    "        data.edge_attr=post\n",
    "        \n",
    "        #####归一化边特征\n",
    "        std_epsilon=torch.tensor([1e-8])\n",
    "        a=torch.mean(data.edge_attr,axis=0,dtype=torch.float32)\n",
    "        b=data.edge_attr.std(dim=0)\n",
    "        b=torch.maximum(b,std_epsilon)\n",
    "        data.edge_attr=(data.edge_attr-a)/b\n",
    "        \n",
    "        data.aoa = aoa\n",
    "        data.norm_aoa = norm_aoa\n",
    "        data.mach_or_reynolds = mach_or_reynolds\n",
    "        data.norm_mach_or_reynolds = norm_mach_or_reynolds\n",
    "        return data\n",
    "\n",
    "    def preprocess(self, tensor_list, stack_output=True):\n",
    "        data_max, data_min = self.normalization_factors\n",
    "        normalized_tensors = []\n",
    "        for i in range(len(tensor_list)):\n",
    "            normalized = (tensor_list[i] - data_min[i]) / (data_max[i] - data_min[i]) * 2 - 1\n",
    "            if type(normalized) is np.ndarray:\n",
    "                normalized = torch.from_numpy(normalized)\n",
    "            normalized_tensors.append(normalized)\n",
    "        if stack_output:\n",
    "            normalized_tensors = torch.stack(normalized_tensors, dim=1)\n",
    "        return normalized_tensors\n",
    "\n",
    "    def _download(self):\n",
    "        pass\n",
    "\n",
    "    def _process(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params_from_name(filename):\n",
    "        s = filename.rsplit('.', 1)[0].split('_')\n",
    "        aoa = np.array(s[s.index('aoa') + 1])[np.newaxis].astype(np.float32)\n",
    "        reynolds = s[s.index('re') + 1]\n",
    "        reynolds = np.array(reynolds)[np.newaxis].astype(np.float32) if reynolds != 'None' else None\n",
    "        mach = np.array(s[s.index('mach') + 1])[np.newaxis].astype(np.float32)\n",
    "        return aoa, reynolds, mach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c166543-a50b-40af-aeab-54b4a85cb53f",
   "metadata": {},
   "source": [
    "### 数据集类 `MeshAirfoilDataset`\n",
    "这是一个继承自 `torch_geometric.data.Dataset` 的类，用于加载和处理空气动力学网格数据。主要功能包括：\n",
    "- **初始化**：读取网格文件，加载归一化因子，初始化节点、边、元素列表和标记字典。\n",
    "- **`__len__`**：返回数据集的长度。\n",
    "- **`get`**：根据索引加载并预处理数据，包括读取物理场数据、归一化处理、添加物理参数到节点特征、计算边特征并归一化。\n",
    "- **`preprocess`**：对物理场数据进行归一化处理。\n",
    "- **`_download` 和 `_process`**：空方法，用于满足 `Dataset` 类的接口要求。\n",
    "- **`get_params_from_name`**：从文件名中提取物理参数（攻角、雷诺数、马赫数）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e1a9204-6749-4abf-9174-925d786eda64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_images(nodes, pred, true, batch, elems_list, mode, log_idx=0,iterate=0,file='field.png'):\n",
    "        inds = batch == log_idx\n",
    "        nodes = nodes[inds]\n",
    "        pred = pred[inds] \n",
    "        true = true[inds]\n",
    "        for field in range(pred.shape[1]):\n",
    "            true_img = plot_field(nodes, elems_list, true[:, field],\n",
    "                                  title='true')\n",
    "            true_img = ToTensor()(true_img)\n",
    "            min_max = (true[:, field].min().item(), true[:, field].max().item())\n",
    "\n",
    "            pred_img = plot_field(nodes, elems_list, pred[:, field],\n",
    "                                  title='pred',clim=min_max)  #clim=min_max \n",
    "            pred_img=ToTensor()(pred_img)\n",
    "            imgs=[pred_img,true_img]  \n",
    "            grid = make_grid(torch.stack(imgs), padding=0) \n",
    "            out_file=file+f'{field}'\n",
    "            utils.save_image(grid,out_file+'_field.png')  \n",
    "        # 释放内存\n",
    "        del true_img, pred_img, grid, imgs\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "def plot_field(nodes, elems_list, field, contour=False, clim=None, zoom=True,\n",
    "               get_array=True, out_file=None, show=False, title=''):\n",
    "    elems_list = sum(elems_list, [])\n",
    "    tris, _ = quad2tri(elems_list)\n",
    "    tris = np.array(tris)\n",
    "    x, y = nodes[:, :2].t().detach().cpu().numpy()\n",
    "    field = field.detach().cpu().numpy()\n",
    "    fig = plt.figure(dpi=800)\n",
    "    if contour:\n",
    "        plt.tricontourf(x, y, tris, field)\n",
    "    else:\n",
    "        plt.tripcolor(x, y, tris, field)\n",
    "    if clim:\n",
    "        plt.clim(*clim)\n",
    "    plt.colorbar()\n",
    "    if zoom:\n",
    "        plt.xlim(left=-0.5, right=1.5)\n",
    "        plt.ylim(bottom=-1.0, top=1.0)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    if out_file is not None:\n",
    "        plt.savefig(out_file)\n",
    "        plt.close()\n",
    "\n",
    "    if show:\n",
    "         plt.show()\n",
    "        #raise NotImplementedError\n",
    "\n",
    "    if get_array:\n",
    "        fig.canvas.draw()\n",
    "        a = np.fromstring(fig.canvas.tostring_rgb(),\n",
    "                          dtype=np.uint8, sep='')\n",
    "        a = a.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        plt.close()\n",
    "        return a\n",
    "    \n",
    "def quad2tri(elems):\n",
    "    new_elems = []\n",
    "    new_edges = []\n",
    "    for e in elems:\n",
    "        if len(e) <= 3:\n",
    "            new_elems.append(e)\n",
    "        else:\n",
    "            new_elems.append([e[0], e[1], e[2]])\n",
    "            new_elems.append([e[0], e[2], e[3]])\n",
    "            new_edges.append(torch.tensor(([[e[0]], [e[2]]]), dtype=torch.long))\n",
    "    new_edges = torch.cat(new_edges, dim=1) if new_edges else torch.tensor([], dtype=torch.long)\n",
    "    return new_elems, new_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093df02-c82a-463d-8454-2cabeb3767fa",
   "metadata": {},
   "source": [
    "### 辅助函数 `log_images`\n",
    "用于将预测和真实的物理场数据可视化并保存为图片。\n",
    "### 辅助函数 `plot_field`\n",
    "用于绘制物理场数据，支持等高线图和颜色填充图，并可以调整显示范围和保存图片。\n",
    "### 辅助函数 `quad2tri`\n",
    "将四边形网格元素转换为三角形网格元素，并返回新的元素列表和边索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f122869e-31f1-437d-abda-c2c6c7958a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: DataBatch(x=[26736, 5], edge_index=[2, 105344], y=[26736, 3], pos=[26736, 2], edge_attr=[105344, 1], aoa=[4], norm_aoa=[4], mach_or_reynolds=[4], norm_mach_or_reynolds=[4], batch=[26736], ptr=[5])\n"
     ]
    }
   ],
   "source": [
    "dataset=[]\n",
    "train_loader=MeshAirfoilDataset('/home/ma-user/work/data/NACA0012_interpolate/',mode='train')\n",
    "for i in range(train_loader.len):\n",
    "    data=train_loader.get(i)\n",
    "    dataset.append(data)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# 从loader中获取一份数据\n",
    "data_batch = next(iter(loader))\n",
    "\n",
    "# 查看数据的形状\n",
    "print(\"Data batch shape:\", data_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61bb438-0861-4b73-ba31-542056e361e3",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0321e3-4a2f-4ce1-ab5b-96076a0f1978",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "Epoch 1/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.0197]\n",
      "Epoch 2/500: 100%|██████████| 42/42 [01:25<00:00,  2.02s/it, loss=0.0309] \n",
      "Epoch 3/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.0203] \n",
      "Epoch 4/500: 100%|██████████| 42/42 [01:25<00:00,  2.02s/it, loss=0.0329] \n",
      "Epoch 5/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.0122] \n",
      "Epoch 6/500: 100%|██████████| 42/42 [01:25<00:00,  2.03s/it, loss=0.0132] \n",
      "Epoch 7/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.0106] \n",
      "Epoch 8/500: 100%|██████████| 42/42 [01:25<00:00,  2.03s/it, loss=0.00979]\n",
      "Epoch 9/500: 100%|██████████| 42/42 [01:25<00:00,  2.03s/it, loss=0.00898]\n",
      "Epoch 10/500: 100%|██████████| 42/42 [01:25<00:00,  2.03s/it, loss=0.00914]\n",
      "Epoch 11/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00672]\n",
      "Epoch 12/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00675]\n",
      "Epoch 13/500: 100%|██████████| 42/42 [01:25<00:00,  2.02s/it, loss=0.00777]\n",
      "Epoch 14/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00314]\n",
      "Epoch 15/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00474]\n",
      "Epoch 16/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00227]\n",
      "Epoch 17/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00306]\n",
      "Epoch 18/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00192]\n",
      "Epoch 19/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000785]\n",
      "Epoch 20/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000747]\n",
      "Epoch 21/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00285] \n",
      "Epoch 22/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00214] \n",
      "Epoch 23/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.0012] \n",
      "Epoch 24/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.0012]  \n",
      "Epoch 25/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000695]\n",
      "Epoch 26/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00207] \n",
      "Epoch 27/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000734]\n",
      "Epoch 28/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000947]\n",
      "Epoch 29/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000742]\n",
      "Epoch 30/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00132] \n",
      "Epoch 31/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.00123] \n",
      "Epoch 32/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.0021]  \n",
      "Epoch 33/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000812]\n",
      "Epoch 34/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00127] \n",
      "Epoch 35/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00134] \n",
      "Epoch 36/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.0011]  \n",
      "Epoch 37/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000864]\n",
      "Epoch 38/500: 100%|██████████| 42/42 [01:25<00:00,  2.03s/it, loss=0.000678]\n",
      "Epoch 39/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00125] \n",
      "Epoch 40/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000255]\n",
      "Epoch 41/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000536]\n",
      "Epoch 42/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000885]\n",
      "Epoch 43/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.0012]  \n",
      "Epoch 44/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00165] \n",
      "Epoch 45/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000264]\n",
      "Epoch 46/500: 100%|██████████| 42/42 [01:25<00:00,  2.02s/it, loss=0.00169] \n",
      "Epoch 47/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000206]\n",
      "Epoch 48/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00105] \n",
      "Epoch 49/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000671]\n",
      "Epoch 50/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00124] \n",
      "Epoch 51/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000339]\n",
      "Epoch 52/500: 100%|██████████| 42/42 [01:25<00:00,  2.03s/it, loss=0.000334]\n",
      "Epoch 53/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.00175] \n",
      "Epoch 54/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00111] \n",
      "Epoch 55/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000946]\n",
      "Epoch 56/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000312]\n",
      "Epoch 57/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.0004]  \n",
      "Epoch 58/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000405]\n",
      "Epoch 59/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000367]\n",
      "Epoch 60/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00108] \n",
      "Epoch 61/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000339]\n",
      "Epoch 62/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000196]\n",
      "Epoch 63/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00019] \n",
      "Epoch 64/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000305]\n",
      "Epoch 65/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000129]\n",
      "Epoch 66/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000213]\n",
      "Epoch 67/500: 100%|██████████| 42/42 [01:25<00:00,  2.02s/it, loss=0.000167]\n",
      "Epoch 68/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000384]\n",
      "Epoch 69/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000134]\n",
      "Epoch 70/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=9.25e-5] \n",
      "Epoch 71/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000576]\n",
      "Epoch 72/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000156]\n",
      "Epoch 73/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.0002]  \n",
      "Epoch 74/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00012] \n",
      "Epoch 75/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000216]\n",
      "Epoch 76/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000141]\n",
      "Epoch 77/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000139]\n",
      "Epoch 78/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=7.25e-5] \n",
      "Epoch 79/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000217]\n",
      "Epoch 80/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000129]\n",
      "Epoch 81/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.00026] \n",
      "Epoch 82/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000159]\n",
      "Epoch 83/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000284]\n",
      "Epoch 84/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000279]\n",
      "Epoch 85/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000121]\n",
      "Epoch 86/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000165]\n",
      "Epoch 87/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000106]\n",
      "Epoch 88/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000332]\n",
      "Epoch 89/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000114]\n",
      "Epoch 90/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000165]\n",
      "Epoch 91/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000123]\n",
      "Epoch 92/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=9.51e-5] \n",
      "Epoch 93/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=7.6e-5]  \n",
      "Epoch 94/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000152]\n",
      "Epoch 95/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000317]\n",
      "Epoch 96/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=9.81e-5] \n",
      "Epoch 97/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=0.000255]\n",
      "Epoch 98/500: 100%|██████████| 42/42 [01:24<00:00,  2.01s/it, loss=0.000114]\n",
      "Epoch 99/500: 100%|██████████| 42/42 [01:24<00:00,  2.02s/it, loss=9.85e-5] \n",
      "Epoch 100/500:  86%|████████▌ | 36/42 [01:12<00:12,  2.02s/it, loss=0.000143]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "summaryWriter=SummaryWriter(\"/home/ma-user/work/logs/log1\")\n",
    "min_nodes = 2000\n",
    "\n",
    "model=EncodeProcessDecode(output_size=3,\n",
    "                 latent_size=128,\n",
    "                 num_layers=2,\n",
    "                 message_passing_aggregator='sum', message_passing_steps=6).to(device)\n",
    "optimizers = optim.Adam(model.parameters(), lr=0.0005)#weight_decay=5e-4\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizers, 0.1 + 1e-6, last_epoch=-1)\n",
    "criterion =torch.nn.MSELoss().to(device)\n",
    "root_logger = logger_setup(os.path.join('/home/ma-user/work/', 'logairfoil.log'))\n",
    "\n",
    "model.train()\n",
    "root_logger.info(\"===========start train===========\") \n",
    "loss_history=[]\n",
    "for epoch in range(500):\n",
    "    sum_loss = 0\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{500}\")  # 添加训练进度条\n",
    "    for batch in pbar:\n",
    "        batch = batch.to(device)\n",
    "        truefield = batch.y\n",
    "        prefield = model(batch)\n",
    "        #if epoch % 9 == 0:\n",
    "            #log_images(batch.pos, prefield, truefield, batch.batch, train_loader.elems_list, 'train')\n",
    "        mes_loss = criterion(prefield, truefield)\n",
    "        optimizers.zero_grad()\n",
    "        mes_loss.backward()\n",
    "        optimizers.step()\n",
    "        loss = mes_loss\n",
    "        sum_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': loss.item()})  # 更新进度条显示的损失值\n",
    "    loss_history.append(sum_loss / len(loader))\n",
    "    sum_loss1 = (sum_loss) / len(loader)\n",
    "    summaryWriter.add_scalar(\"loss\", math.sqrt(sum_loss1), epoch)\n",
    "    root_logger.info(\"        trajectory_loss\")\n",
    "    root_logger.info(\"        \" + str(sum_loss1))\n",
    "    if (epoch == 60) | (epoch == 100) | (epoch == 140) | (epoch == 170):\n",
    "        scheduler.step()\n",
    "\n",
    "torch.save(model.state_dict(), '/home/ma-user/work/result/modelairfoil.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa3d992-8efb-4750-9f35-144d1bccbc05",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14b7d479-e06c-4e1c-9ac2-cadac12f9a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "Testing:  63%|██████▎   | 40/63 [00:59<00:33,  1.48s/it, loss=0.00755]/home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages/ipykernel/__main__.py:56: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "Testing: 100%|██████████| 63/63 [07:11<00:00,  6.84s/it, loss=0.0216] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 该部分生成图像时可能因为内存原因中断，请手动拆分为两部分进行生成\n",
    "device = torch.device(\"cuda:0\")\n",
    "summaryWriter=SummaryWriter(\"/home/ma-user/work/logs/log1\")\n",
    "\n",
    "model=EncodeProcessDecode(output_size=3,\n",
    "                 latent_size=128,\n",
    "                 num_layers=2,\n",
    "                 message_passing_aggregator='sum', message_passing_steps=6).to(device)\n",
    "model.load_state_dict(torch.load('/home/ma-user/work/result/modelairfoil.pkl'))      \n",
    "min_nodes = 2000\n",
    "\n",
    "dataset_test=[]\n",
    "test_loader=MeshAirfoilDataset('/home/ma-user/work/data/NACA0012_interpolate/',mode='test')\n",
    "for i in range(test_loader.len):\n",
    "    data=test_loader.get(i)\n",
    "    dataset_test.append(data)\n",
    "test_loader = DataLoader(dataset_test, batch_size=1, shuffle=True)\n",
    "\n",
    "optimizers = optim.Adam(model.parameters(), lr=0.0005)#weight_decay=5e-4\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizers, 0.1 + 1e-6, last_epoch=-1)\n",
    "criterion =torch.nn.MSELoss().to(device)\n",
    "root_logger = logger_setup(os.path.join('/home/ma-user/work/', 'logairfoil.log'))\n",
    "\n",
    "model.eval()\n",
    "root_logger.info(\"===========start test===========\") \n",
    "with torch.no_grad():\n",
    "    sum_loss = 0\n",
    "    pbar = tqdm(test_loader, desc=\"Testing\")  # 添加测试进度条\n",
    "    pic_id = 0\n",
    "    for batch in pbar:\n",
    "        batch = batch.to(device)\n",
    "        truefield = batch.y\n",
    "        prefield = model(batch)\n",
    "        pic_name = 'result_pic/test_pic' + str(pic_id) + '_'\n",
    "        pic_id += 1\n",
    "        if pic_id >= 0:\n",
    "            log_images(batch.pos, prefield, truefield, batch.batch, train_loader.elems_list, 'test', file=pic_name)\n",
    "        mes_loss = criterion(prefield, truefield)\n",
    "        loss = mes_loss.cpu()\n",
    "        loss = np.sqrt(loss)\n",
    "        sum_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': loss.item()})  # 更新进度条显示的损失值\n",
    "sum_loss1 = sum_loss / (len(test_loader))\n",
    "root_logger.info(\"        trajectory_loss\")\n",
    "root_logger.info(\"        \" + str(sum_loss1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b7faa-8b97-4f84-9bfd-db8dec9ba48b",
   "metadata": {},
   "source": [
    "# Cylinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac72bf1-5145-45db-a0b8-9f8da60aa064",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66c97a07-e756-40f4-9863-efa1e5ec506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import math,copy\n",
    "from os import PathLike\n",
    "from typing import Sequence, Dict, Union, Tuple, List\n",
    "import torch\n",
    "from torch._six import string_classes\n",
    "import collections.abc as container_abcs\n",
    "from torch_geometric.data import Data, Batch, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from scipy.spatial.qhull import Delaunay\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import utils\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7b2d263-f4a2-49da-bbed-803d938b54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "SU2_SHAPE_IDS = {\n",
    "    'line': 3,\n",
    "    'triangle': 5,\n",
    "    'quad': 9,\n",
    "}\n",
    "def get_mesh_graph(mesh_filename: Union[str, PathLike],\n",
    "                   dtype: np.dtype = np.float32\n",
    "                   ) -> Tuple[np.ndarray, np.ndarray, List[List[List[int]]], Dict[str, List[List[int]]]]:\n",
    "    def get_rhs(s: str) -> str:\n",
    "        return s.split('=')[-1]\n",
    "\n",
    "    marker_dict = {}\n",
    "    with open(mesh_filename) as f:\n",
    "        for line in f:\n",
    "            if line.startswith('NPOIN'):\n",
    "                num_points = int(get_rhs(line))\n",
    "                mesh_points = [[float(p) for p in f.readline().split()[:2]]\n",
    "                               for _ in range(num_points)]\n",
    "                nodes = np.array(mesh_points, dtype=dtype)\n",
    "\n",
    "            if line.startswith('NMARK'):\n",
    "                num_markers = int(get_rhs(line))\n",
    "                for _ in range(num_markers):\n",
    "                    line = f.readline()\n",
    "                    assert line.startswith('MARKER_TAG')\n",
    "                    marker_tag = get_rhs(line).strip()\n",
    "                    num_elems = int(get_rhs(f.readline()))\n",
    "                    marker_elems = [[int(e) for e in f.readline().split()[-2:]]\n",
    "                                    for _ in range(num_elems)]\n",
    "                    marker_dict[marker_tag] = marker_elems\n",
    "\n",
    "            if line.startswith('NELEM'):\n",
    "                edges = []\n",
    "                triangles = []\n",
    "                quads = []\n",
    "                num_edges = int(get_rhs(line))\n",
    "                for _ in range(num_edges):\n",
    "                    elem = [int(p) for p in f.readline().split()]\n",
    "                    if elem[0] == SU2_SHAPE_IDS['triangle']:\n",
    "                        n = 3\n",
    "                        triangles.append(elem[1:1+n])\n",
    "                    elif elem[0] == SU2_SHAPE_IDS['quad']:\n",
    "                        n = 4\n",
    "                        quads.append(elem[1:1+n])\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "                    elem = elem[1:1+n]\n",
    "                    edges += [[elem[i], elem[(i+1) % n]] for i in range(n)]\n",
    "                edges = np.array(edges, dtype=np.long).transpose()\n",
    "                elems = [triangles, quads]\n",
    "\n",
    "\n",
    "    return nodes, edges, elems, marker_dict\n",
    "\n",
    "class MeshcylinderDataset(Dataset):\n",
    "    def __init__(self, root, mode='train'):\n",
    "        self.mode = mode\n",
    "        self.data_dir = Path(root) / (mode)\n",
    "        self.file_list = [f for f in os.listdir(self.data_dir) if '.ipynb_checkpoints' not in f]\n",
    "        self.len = len(self.file_list)\n",
    "\n",
    "        self.mesh_graph = get_mesh_graph(Path(root) / 'cylinder.su2')\n",
    "\n",
    "        self.normalization_factors =torch.tensor([[978.6001,  48.9258,  24.8404],\n",
    "        [-692.3159,   -6.9950,  -24.8572]])\n",
    "        self.nodes = torch.from_numpy(self.mesh_graph[0])\n",
    "        self.meshnodes=self.mesh_graph[0]\n",
    "        self.edges = torch.from_numpy(self.mesh_graph[1])\n",
    "        self.elems_list = self.mesh_graph[2]\n",
    "        self.marker_dict = self.mesh_graph[3]\n",
    "        self.bounder=[]\n",
    "        self.node_markers = self.nodes.new_full((self.nodes.shape[0], 1), fill_value=-1)\n",
    "        for i, (marker_tag, marker_elems) in enumerate(self.marker_dict.items()):\n",
    "            for elem in marker_elems:\n",
    "                self.node_markers[elem[0]] = i\n",
    "                self.node_markers[elem[1]] = i\n",
    "\n",
    "        super().__init__(root)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def get(self, idx):\n",
    "        with open(self.data_dir/self.file_list[idx],'r') as f:\n",
    "            field=[]\n",
    "            pos=[]\n",
    "            i=1\n",
    "            for lines in f.readlines():\n",
    "                if not i: \n",
    "                    lines=lines.rstrip('\\n')\n",
    "                    lines_pos=lines.split(',')[1:3]\n",
    "                    lines_field=lines.split(',')[3:]\n",
    "                    #for i in range(len(lines)):\n",
    "                    #    a=float(lines[i])\n",
    "                    numbers_float =list(eval(i) for i in lines_pos)\n",
    "                    array=np.array(numbers_float,np.float32)\n",
    "                    a=torch.from_numpy(array) \n",
    "                    pos.append(a)\n",
    "                    numbers_float =list(eval(i) for i in lines_field)\n",
    "                    array=np.array(numbers_float,np.float32)\n",
    "                    a=torch.from_numpy(array) \n",
    "                    field.append(a)\n",
    "                i=0\n",
    "        field=torch.stack(field,axis=0)\n",
    "        pos= torch.stack(pos,axis=0)       \n",
    "        indexlist=[]\n",
    "        for i in range(self.meshnodes.shape[0]):\n",
    "            b=torch.from_numpy(self.meshnodes[i:(i+1)])\n",
    "            b=torch.squeeze(b)\n",
    "            index=torch.nonzero(torch.sum((pos==b),axis=1,dtype=torch.float32)==pos.shape[1])\n",
    "            indexlist.append(index)    \n",
    "        indexlist=torch.stack(indexlist,axis=0)\n",
    "        indexlist=torch.squeeze(indexlist)\n",
    "        fields=field[indexlist]\n",
    "\n",
    "        velocity= self.get_params_from_name(self.file_list[idx])\n",
    "        aoa = torch.from_numpy(velocity)\n",
    "\n",
    "        norm_aoa = (aoa/40)\n",
    "        nodes = torch.cat([\n",
    "            self.nodes,\n",
    "            norm_aoa.unsqueeze(0).repeat(self.nodes.shape[0], 1),\n",
    "            self.node_markers\n",
    "        ], dim=-1).to(torch.float32)\n",
    "\n",
    "        data = Data(x=nodes, y=fields, edge_index=self.edges,pos=self.nodes,velocity=aoa)\n",
    "\n",
    "        sender=data.x[data.edge_index[0]]\n",
    "        receiver=data.x[data.edge_index[1]]\n",
    "        relation_pos=sender[:,0:2]-receiver[:,0:2]\n",
    "        post=torch.norm(relation_pos,p=2,dim=1,keepdim=True)\n",
    "        data.edge_attr=post\n",
    "        # 边特征归一化\n",
    "        std_epsilon=torch.tensor([1e-8])\n",
    "        a=torch.mean(data.edge_attr,axis=0,dtype=torch.float32)\n",
    "        b=data.edge_attr.std(dim=0)\n",
    "        b=torch.maximum(b,std_epsilon)\n",
    "        data.edge_attr=(data.edge_attr-a)/b\n",
    "        \n",
    "        a=torch.mean(data.y,axis=0,dtype=torch.float32)\n",
    "        b=data.y.std(dim=0)\n",
    "        b=torch.maximum(b,std_epsilon)\n",
    "        data.y=(data.y-a)/b\n",
    "        \n",
    "        data.norm_max = a\n",
    "        data.norm_min = b\n",
    "        \n",
    "        # y_min = torch.min(data.y, dim=0).values\n",
    "        # y_max = torch.max(data.y, dim=0).values\n",
    "        # data.y = 2 * (data.y - y_min) / (y_max - y_min) - 1\n",
    "        # data.norm_min = y_min\n",
    "        # data.norm_max = y_max\n",
    "        \n",
    "        with open('/home/ma-user/work/data/cylinderdata/bounder','r') as f:\n",
    "            field=[]\n",
    "            pos=[]\n",
    "            i=1\n",
    "            for lines in f.readlines():\n",
    "                if not i: \n",
    "                    lines=lines.rstrip('\\n')\n",
    "                    lines_pos=lines.split(',')[1:3]\n",
    "                    lines_field=lines.split(',')[3:]\n",
    "                    numbers_float =list(eval(i) for i in lines_pos)\n",
    "                    array=np.array(numbers_float,np.float32)\n",
    "                    a=torch.from_numpy(array) \n",
    "                    pos.append(a)\n",
    "                    numbers_float =list(eval(i) for i in lines_field)\n",
    "                    array=np.array(numbers_float,np.float32)\n",
    "                    a=torch.from_numpy(array) \n",
    "                    field.append(a)\n",
    "                i=0\n",
    "        field=torch.stack(field,axis=0)\n",
    "        pos= torch.stack(pos,axis=0)       \n",
    "        indexlist=[]\n",
    "        for i in range(pos.shape[0]):\n",
    "            b=pos[i:(i+1)]\n",
    "            b=torch.squeeze(b)\n",
    "            index=torch.nonzero(torch.sum((self.nodes==b),dim=1,dtype=torch.float32)==self.nodes.shape[1])\n",
    "            indexlist.append(index) \n",
    "        indexlist=torch.stack(indexlist,dim=0)\n",
    "        indexlist=torch.squeeze(indexlist)\n",
    "        self.bounder=indexlist\n",
    "        return data\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_params_from_name(filename):\n",
    "        s = filename.rsplit('.', 1)[0]\n",
    "        reynolds = np.array(s[13:])[np.newaxis].astype(np.float32)\n",
    "        return reynolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32d92f8d-1d74-4a49-a5f6-c83afd66a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_images(nodes, pred, true, batch, elems_list, mode, log_idx=0,iterate=0,file='field.png'):\n",
    "        inds = batch == log_idx\n",
    "        nodes = nodes[inds]\n",
    "        pred = pred[inds] \n",
    "        true = true[inds]\n",
    "        for field in range(pred.shape[1]):\n",
    "            # min_max = (-0.8, 0.8)\n",
    "\n",
    "            true_img = plot_field(nodes, elems_list, true[:, field],\n",
    "                                  title='true')\n",
    "            true_img = ToTensor()(true_img)\n",
    "            \n",
    "            min_max = (true[:, field].min().item(), true[:, field].max().item())\n",
    "\n",
    "            pred_img = plot_field(nodes, elems_list, pred[:, field],\n",
    "                                  title='pred',clim=min_max)  #clim=min_max \n",
    "            pred_img=ToTensor()(pred_img)\n",
    "            \n",
    "            imgs=[pred_img,true_img]  \n",
    "            grid = make_grid(torch.stack(imgs), padding=0) \n",
    "            out_file=file+f'{field}'\n",
    "            utils.save_image(grid,out_file+'_field.png')  \n",
    "        # 释放内存\n",
    "        del true_img, pred_img, grid, imgs\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "def plot_field(nodes, elems_list, field, contour=False, clim=None, zoom=True,\n",
    "               get_array=True, out_file=None, show=False, title=''):\n",
    "    elems_list = sum(elems_list, [])\n",
    "    tris, _ = quad2tri(elems_list)\n",
    "    tris = np.array(tris)\n",
    "    x, y = nodes[:, :2].t().detach().cpu().numpy()\n",
    "    field = field.detach().cpu().numpy()\n",
    "    fig = plt.figure(dpi=800)\n",
    "    if contour:\n",
    "        plt.tricontourf(x, y, tris, field)\n",
    "    else:\n",
    "        plt.tripcolor(x, y, tris, field)\n",
    "    if clim:\n",
    "        plt.clim(*clim)\n",
    "    plt.colorbar()\n",
    "    if zoom:\n",
    "        plt.xlim(left=-3.0, right=3.0)\n",
    "        plt.ylim(bottom=-3.0, top=3.0)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    if out_file is not None:\n",
    "        plt.savefig(out_file)\n",
    "        plt.close()\n",
    "\n",
    "    if show:\n",
    "         plt.show()\n",
    "        #raise NotImplementedError\n",
    "\n",
    "    if get_array:\n",
    "        fig.canvas.draw()\n",
    "        a = np.fromstring(fig.canvas.tostring_rgb(),\n",
    "                          dtype=np.uint8, sep='')\n",
    "        a = a.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "        plt.close()\n",
    "        return a\n",
    "    \n",
    "def quad2tri(elems):\n",
    "    new_elems = []\n",
    "    new_edges = []\n",
    "    for e in elems:\n",
    "        if len(e) <= 3:\n",
    "            new_elems.append(e)\n",
    "        else:\n",
    "            new_elems.append([e[0], e[1], e[2]])\n",
    "            new_elems.append([e[0], e[2], e[3]])\n",
    "            new_edges.append(torch.tensor(([[e[0]], [e[2]]]), dtype=torch.long))\n",
    "    new_edges = torch.cat(new_edges, dim=1) if new_edges else torch.tensor([], dtype=torch.long)\n",
    "    return new_elems, new_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c8195a5-8249-49ef-b7ce-4a1d14aeef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=[]\n",
    "train_loader=MeshcylinderDataset('/home/ma-user/work/data/cylinderdata',mode='train')\n",
    "for i in range(train_loader.len): \n",
    "    data=train_loader.get(i)\n",
    "    dataset.append(data)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "dataset_test = []\n",
    "test_loader_=MeshcylinderDataset('/home/ma-user/work/data/cylinderdata',mode='test')\n",
    "for i in range(test_loader_.len):\n",
    "    data = test_loader_.get(i)\n",
    "    dataset_test.append(data)\n",
    "test_loader = DataLoader(dataset_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "671f9060-5858-4d4f-a448-3cf51106782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-10.0000, -20.0000,   0.9375,   0.0000],\n",
      "        [ -8.2759, -20.0000,   0.9375,   0.0000],\n",
      "        [ -6.5517, -20.0000,   0.9375,   0.0000],\n",
      "        ...,\n",
      "        [  1.8668,  -0.4482,   0.9375,  -1.0000],\n",
      "        [  1.9014,  -0.3012,   0.9375,  -1.0000],\n",
      "        [  1.9139,  -0.1506,   0.9375,  -1.0000]])\n",
      "tensor([[ 2.8666e-01,  7.6498e-01,  4.5367e-04],\n",
      "        [ 2.8341e-01,  7.6681e-01,  4.5367e-04],\n",
      "        [ 2.7564e-01,  7.7028e-01,  4.5367e-04],\n",
      "        ...,\n",
      "        [-8.6706e-01, -1.6042e+00, -1.7251e-01],\n",
      "        [-8.6152e-01, -1.6480e+00, -1.2177e-01],\n",
      "        [-8.5795e-01, -1.6721e+00, -6.3587e-02]])\n",
      "tensor([37.5000])\n"
     ]
    }
   ],
   "source": [
    "data = train_loader.get(0)\n",
    "print(data.x)\n",
    "print(data.y)\n",
    "print(data.velocity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f07b7e-3889-489a-922a-852d813a7b31",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1bcc62-4cae-4b39-942c-aa70938efa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "model=EncodeProcessDecode(output_size=3,\n",
    "                 latent_size=128,\n",
    "                 num_layers=2,\n",
    "                 message_passing_aggregator='sum', message_passing_steps=6).to(device)\n",
    "\n",
    "optimizers = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizers, gamma=0.1)\n",
    "criterion =torch.nn.MSELoss().to(device)\n",
    "\n",
    "pre_loss = 100\n",
    "min_nodes = 20000\n",
    "\n",
    "for epoch in range(500):\n",
    "    \n",
    "    model.train()\n",
    "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1}/{500}\")  # 添加训练进度条\n",
    "    for batch in pbar:\n",
    "        batch = batch.to(device)\n",
    "        truefield = batch.y\n",
    "        batch.x = batch.x.to(torch.float32)\n",
    "        batch.velocity = batch.velocity.to(torch.float32)\n",
    "        batch.edge_attr = batch.edge_attr.to(torch.float32)\n",
    "        prefield = model(batch)\n",
    "        \n",
    "        mes_loss = criterion(prefield, truefield)\n",
    "        optimizers.zero_grad()\n",
    "        mes_loss.backward()\n",
    "        optimizers.step()\n",
    "        loss = mes_loss\n",
    "        pbar.set_postfix({'loss': loss.item()}) \n",
    "        \n",
    "    sum_loss = 0\n",
    "    model.eval()\n",
    "    test_tqdm = tqdm(test_loader, desc=\"Testing\")\n",
    "    with torch.no_grad():\n",
    "        for batch in test_tqdm:\n",
    "            batch = batch.to(device)\n",
    "            truefield = batch.y\n",
    "            batch.x = batch.x.to(torch.float32)\n",
    "            batch.velocity = batch.velocity.to(torch.float32)\n",
    "            batch.edge_attr = batch.edge_attr.to(torch.float32)\n",
    "            prefield = model(batch)\n",
    "\n",
    "            test_mes_loss = criterion(prefield, truefield)\n",
    "            test_loss = test_mes_loss.cpu()\n",
    "            test_loss = np.sqrt(test_loss)\n",
    "            sum_loss += test_loss.item()\n",
    "            test_tqdm.set_postfix({'loss': test_loss.item()}) \n",
    "            \n",
    "    if((epoch==60)|(epoch==100)|(epoch==140)|(epoch==170)): \n",
    "        scheduler.step()\n",
    "        \n",
    "    if sum_loss < pre_loss:\n",
    "        pre_loss = sum_loss\n",
    "        torch.save(model.state_dict(), '/home/ma-user/work/result/modelcylinder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815108c9-5529-4d9b-b9cb-ea4e60cf4c71",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6128aa58-9801-404e-b84b-7864c20cce42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/11 [00:00<?, ?it/s]/home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages/ipykernel/__main__.py:60: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "Testing:  82%|████████▏ | 9/11 [02:11<00:28, 14.17s/it, loss=0.0501]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "summaryWriter=SummaryWriter(\"logs/log2\")\n",
    "\n",
    "model=EncodeProcessDecode(output_size=3,\n",
    "                 latent_size=128,\n",
    "                 num_layers=2,\n",
    "                 message_passing_aggregator='sum', message_passing_steps=6).to(device)\n",
    "model.load_state_dict(torch.load('/home/ma-user/work/result/modelcylinder.pkl'))  \n",
    "# model.load_state_dict(torch.load('/home/ma-user/work/result/modelairfoil.pkl'))  \n",
    "\n",
    "min_nodes = 20000\n",
    "\n",
    "optimizers = optim.Adam(model.parameters(), lr=0.0001)#weight_decay=5e-4\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizers, 0.1 + 1e-6, last_epoch=-1)\n",
    "criterion =torch.nn.MSELoss().to(device)\n",
    "root_logger = logger_setup(os.path.join('/home/ma-user/work', 'log_cylinder_test.log'))\n",
    "\n",
    "root_logger.info(\"===========start test===========\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sum_loss = 0\n",
    "    # 使用 tqdm 添加进度条\n",
    "    pic_id = 0\n",
    "    \n",
    "    test_tqdm = tqdm(test_loader, desc=\"Testing\")\n",
    "    for batch in test_tqdm:\n",
    "        batch = batch.to(device)\n",
    "        truefield = batch.y\n",
    "        batch.x = batch.x.to(torch.float32)\n",
    "        batch.velocity = batch.velocity.to(torch.float32)\n",
    "        batch.edge_attr = batch.edge_attr.to(torch.float32)\n",
    "        prefield = model(batch)\n",
    "        \n",
    "        pic_name = 'cylinder_result_pic/test_pic' + str(pic_id) + '_'\n",
    "        pic_id += 1\n",
    "        if pic_id >= 0:\n",
    "            log_images(batch.pos, prefield, truefield, batch.batch, train_loader.elems_list, 'test', file=pic_name)\n",
    "\n",
    "        # print(prefield, truefield)\n",
    "        mes_loss = criterion(prefield, truefield)\n",
    "        loss = mes_loss.cpu()\n",
    "        loss = np.sqrt(loss)\n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "        test_tqdm.set_postfix({'loss': loss.item()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a2546-05ca-4f09-b88c-0bdf44f05e96",
   "metadata": {},
   "source": [
    "### 数据后处理\n",
    "打包数据与上传obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4c75dcd7-aa63-4a36-9831-611eaf83c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def zip_folder(folder_path, zip_path):\n",
    "    \"\"\"\n",
    "    压缩指定的文件夹到ZIP文件中。\n",
    "\n",
    "    :param folder_path: 要压缩的文件夹路径\n",
    "    :param zip_path: 生成的ZIP文件路径\n",
    "    \"\"\"\n",
    "    # 确保文件夹路径以斜杠结束\n",
    "    folder_path = folder_path.rstrip('/') + '/'\n",
    "\n",
    "    # 创建ZIP文件\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # 遍历文件夹\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                # 获取文件的完整路径\n",
    "                file_path = os.path.join(root, file)\n",
    "                # 计算在ZIP文件中的相对路径\n",
    "                relative_path = os.path.relpath(file_path, folder_path)\n",
    "                # 将文件添加到ZIP文件中\n",
    "                zipf.write(file_path, relative_path)\n",
    "\n",
    "# 示例使用\n",
    "folder_to_zip = '/home/ma-user/work/cylinder_result_pic'  # 要压缩的文件夹路径\n",
    "output_zip_file = '/home/ma-user/work/cylinder_result_pic.zip'  # 输出的ZIP文件路径\n",
    "zip_folder(folder_to_zip, output_zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84b9e3c3-fa00-4409-a687-aa189ea008ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Using MoXing-v2.1.0.5d9c87c8-5d9c87c8\n",
      "INFO:root:Using OBS-Python-SDK-3.20.9.1\n",
      "/home/ma-user/anaconda3/envs/PyTorch-1.10.2/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import moxing as mox\n",
    "mox.file.copy('/home/ma-user/work/result_pic.zip', 'obs://dirlity/Out/result_pic.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906875b-9589-434a-b96f-debf00514732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.10.2",
   "language": "python",
   "name": "pytorch-1.10.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
